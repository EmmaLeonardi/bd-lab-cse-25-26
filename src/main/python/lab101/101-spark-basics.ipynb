{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd7243a-b7d3-4e47-b3ec-49cafdebada5",
   "metadata": {},
   "source": [
    "# 101 Spark basics\n",
    "\n",
    "The goal of this lab is to get familiar with Spark programming.\n",
    "\n",
    "- Scala\n",
    "    - [Spark programming guide](https://spark.apache.org/docs/latest/rdd-programming-guide.html)\n",
    "    - [RDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/RDD.html)\n",
    "    - [PairRDD APIs](https://spark.apache.org/docs/latest/api/scala/org/apache/spark/rdd/PairRDDFunctions.html)\n",
    "- Python\n",
    "    - [Spark programming guide](https://spark.apache.org/docs/3.5.0/rdd-programming-guide.html)\n",
    "    - [All RDD APIs](https://spark.apache.org/docs/3.5.0/api/python/reference/api/pyspark.RDD.html)\n",
    "\n",
    "Use `Tab` for autocompletion, `Shift+Tab` for documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11bb4f39692d0432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:12:01.893550Z",
     "start_time": "2024-10-20T13:11:46.380948Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e281923de95ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://56c2200ceb2e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Local Spark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local appName=Local Spark>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local\") \\\n",
    "    .appName(\"Local Spark\") \\\n",
    "    .config('spark.ui.port', '4040') \\\n",
    "    .getOrCreate()\n",
    "sc = spark.sparkContext\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f9a0be28e5e823",
   "metadata": {},
   "source": [
    "## 101-1 Spark warm-up\n",
    "\n",
    "Load the ```capra``` and ```divinacommedia``` datasets and try the following actions:\n",
    "- Show their content (```collect```)\n",
    "- Count their rows (```count```)\n",
    "- Split phrases into words (```map``` or ```flatMap```; what’s the difference?)\n",
    "- Check the results (remember: evaluation is lazy)\n",
    "- Try the ```toDebugString``` function to check the execution plan\n",
    "    - In PySpark, use ```toDebugString().decode(\"unicode_escape\")```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cbc4b5cee4a93755",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:25:49.644422Z",
     "start_time": "2024-10-20T13:25:49.169096Z"
    }
   },
   "outputs": [],
   "source": [
    "rddCapra = sc.textFile(\"../../../../datasets/capra.txt\")\n",
    "rddDC = sc.textFile(\"../../../../datasets/divinacommedia.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99dcb0ce-3abd-47a5-ad47-2a95846f6eed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:25:49.644422Z",
     "start_time": "2024-10-20T13:25:49.169096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) PythonRDD[6] at collect at /tmp/ipykernel_476/3149173467.py:6 []\n",
      " |  ../../../../datasets/capra.txt MapPartitionsRDD[1] at textFile at NativeMethodAccessorImpl.java:0 []\n",
      " |  ../../../../datasets/capra.txt HadoopRDD[0] at textFile at NativeMethodAccessorImpl.java:0 []\n"
     ]
    }
   ],
   "source": [
    "rddCapra.collect()\n",
    "rddDC.collect()\n",
    "rddCapra.count()\n",
    "rddDC.count()\n",
    "rddCapraSplit=rddCapra.flatMap(lambda x: x.split(\" \"))\n",
    "rddCapraSplit.collect()\n",
    "rddDCSplit=rddDC.flatMap(lambda x: x.split(\" \")).filter(lambda x: len(x)>0) #Remove empty chars\n",
    "#FlatMap returns a listof elements, while map returns a list of lists with each row as a list\n",
    "print(rddCapraSplit.toDebugString().decode(\"unicode_escape\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d04659ace472d8",
   "metadata": {},
   "source": [
    "## 101-2 Basic Spark jobs\n",
    "\n",
    "Implement on Spark the following jobs and test them on both capra and divinacommedia datasets.\n",
    "\n",
    "- **Word count**: count the number of occurrences of each word\n",
    "  - Result: (sopra, 1), (la, 4), …\n",
    "- **Word length count**: count the number of occurrences of words of given lengths\n",
    "  - Result: (2, 4), (5, 8)\n",
    "- Count the average length of words given their first letter (i.e., words that begin with \"s\" have an average length of 5)\n",
    "  - Result: (s, 5), (l, 2), …\n",
    "- Return the inverted index of words (i.e., for each word, list the numbers of lines in which they appear)\n",
    "  - Result: (sopra, (0)), (la, (0, 1)), ...\n",
    "\n",
    "Also, check how sorting works and try to sort key-value RDDs by descending values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d387083-518c-4d20-88a1-7f4b440a3aa2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-20T13:25:49.644422Z",
     "start_time": "2024-10-20T13:25:49.169096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sopra', [0]),\n",
       " ('la', [0, 1]),\n",
       " ('panca', [0, 1]),\n",
       " ('capra', [0, 1]),\n",
       " ('campa', [0]),\n",
       " ('sotto', [1]),\n",
       " ('crepa', [1])]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Word Count\n",
    "rddCapraSplit.map(lambda x: (x, 1)).reduceByKey(lambda x,y: (x+y))\n",
    "rddDCSplit.map(lambda x: (x, 1)).reduceByKey(lambda x,y: (x+y))\n",
    "#Word Lenght Count\n",
    "rddCapraSplit.map(lambda x: (len(x), 1)).reduceByKey(lambda x,y: (x+y))\n",
    "rddDCSplit.map(lambda x: (len(x), 1)).reduceByKey(lambda x,y: (x+y))\n",
    "#Average length of words given their first letter\n",
    "rddCapraSplit.map(lambda x: (x[0], (len(x), 1))).reduceByKey(lambda x,y:(x[0]+y[0], x[1]+y[1])).map(lambda x: (x[0], x[1][0]/x[1][1]))\n",
    "rddDCSplit.map(lambda x: (x[0], (len(x), 1))).reduceByKey(lambda x,y:(x[0]+y[0], x[1]+y[1])).mapValues(lambda x: x[0]/x[1])\n",
    "#Return the inverted index of words\n",
    "rddCapra.map(lambda x: x.split(\" \")).zipWithIndex().map(lambda x: (x[1], x[0])).flatMapValues(lambda list: list).map(lambda x: (x[1], x[0])).distinct().groupByKey().mapValues(lambda v: list(v)).collect()\n",
    "\n",
    "rddCapra.map(lambda x: x.split(\" \")).zipWithIndex().flatMap(lambda el: [(w, el[1])for w in el[0]]).distinct().groupByKey().mapValues(lambda v: list(v)).collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83c49c3689d65e2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 101-3 Extra Spark jobs\n",
    "\n",
    "Implement the following job.\n",
    "\n",
    "- Co-occurrence count: count the number of co-occurrences in the text. A co-occurrence is defined as \"two distinct words appearing in the same line\".\n",
    "  - In the first line of the *capra* dataset, co-occurrences are:\n",
    "     - (sopra, la), (sopra, panca), (sopra, capra), (sopra, campa)\n",
    "     - (la, sopra), (la, panca), (la, capra), (la, campa) \n",
    "     - (panca, sopra), (panca, la), (panca, capra), (panca, campa)\n",
    "     - (capra, sopra), (capra, la), (capra, panca), (capra, campa)\n",
    "     - (campa, sopra), (campa, la), (campa, panca), (campa, capra)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
